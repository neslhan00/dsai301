{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPG8EwoQl+JkgyDDFLjBROD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neslhan00/dsai301/blob/main/Web_Crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neslihan GÃ¼l"
      ],
      "metadata": {
        "id": "GwJL-lpuiGRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WEB CRAWLER PROJECT\n",
        "# As part of my project, I designed a web crawler to index a website, extract links, and rank pages based on their relevance.\n",
        "# This tool simulates how a search engine works by crawling through a given website, gathering all the linked pages,\n",
        "# and ranking them using a modified version of Google's PageRank algorithm."
      ],
      "metadata": {
        "id": "D43tISvXa1LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions:\n",
        "# I wrote the get_page function to fetch the page content\n",
        "def get_page(url):\n",
        "    try:\n",
        "        import urllib.request\n",
        "        page = urllib.request.urlopen(url).read()\n",
        "        page = page.decode(\"utf-8\")\n",
        "        return page\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "# I wrote the get_next_target function to extract links from the page content\n",
        "def get_next_target(page):\n",
        "    start_link = page.find('<a href=')  # Find the start of the link\n",
        "    if start_link == -1:\n",
        "        return None, 0  # Return None if no link is found\n",
        "    start_quote = page.find('\"', start_link)\n",
        "    end_quote = page.find('\"', start_quote + 1)\n",
        "    url = page[start_quote + 1:end_quote]  # Extract the URL from the quotes\n",
        "    return url, end_quote\n",
        "\n",
        "# I wrote the get_all_links function to get all the links from the page content\n",
        "def get_all_links(page):\n",
        "    links = []\n",
        "    while True:\n",
        "        url, endpos = get_next_target(page)  # Extract the next link\n",
        "        if url:\n",
        "            links.append(url)  # Add the link to the list\n",
        "            page = page[endpos:]  # Update the page content to the remaining part\n",
        "        else:\n",
        "            break  # Stop the loop when no more links are found\n",
        "    return links\n",
        "\n",
        "def union(p, q):\n",
        "    for e in q:\n",
        "        if e not in p:\n",
        "            p.append(e)\n",
        "\n",
        "# I wrote the add_toIndex function to add page URLs associated with a keyword to the index\n",
        "def add_toIndex(index, keyword, url):\n",
        "    if keyword in index:\n",
        "        index[keyword].append(url)  # Append the URL to the keyword's list\n",
        "    else:\n",
        "        index[keyword] = [url]  # Add a new entry for the keyword with the URL\n",
        "\n",
        "# I wrote the getclearpage function to clean up the content by removing unnecessary HTML tags\n",
        "def getclearpage(content):\n",
        "    title = content[content.find(\"<title>\") + 7:content.find(\"</title>\")]\n",
        "    body = content[content.find(\"<body>\") + 6:content.find(\"</body>\")]\n",
        "    while body.find(\">\") != -1:\n",
        "        start = body.find(\"<\")\n",
        "        end = body.find(\">\")\n",
        "        body = body[:start] + body[end + 1:]  # Remove tags from the body content\n",
        "    return title + body  # Return the cleaned content with title and body\n",
        "\n",
        "# I wrote the addPageToIndex function to add cleaned page content to the index\n",
        "def addPageToIndex(index, url, content):\n",
        "    content = getclearpage(content)  # Clean the page content\n",
        "    words = content.split()  # Split the content into words\n",
        "    for word in words:\n",
        "        add_toIndex(index, word, url)  # Add each word's associated URL to the index\n",
        "\n",
        "\n",
        "# I wrote the crawlWeb function to start crawling from a seed URL and build the index and graph\n",
        "def crawlWeb(seed):\n",
        "    tocrawl = [seed]  # Initialize the list of pages to crawl\n",
        "    crawled = []  # List of crawled pages\n",
        "    index = {}  # Index to store keyword-page mappings\n",
        "    graph = {}  # Graph to store the links between pages\n",
        "    while tocrawl:\n",
        "        page = tocrawl.pop()  # Get the next page to crawl\n",
        "        if page not in crawled:\n",
        "            content = get_page(page)  # Get the page content\n",
        "            addPageToIndex(index, page, content)  # Add the page content to the index\n",
        "            outlinks = get_all_links(content)  # Extract the links from the page\n",
        "            graph[page] = outlinks  # Add the page and its outlinks to the graph\n",
        "            union(tocrawl, outlinks)  # Add the outlinks to the pages to crawl\n",
        "            crawled.append(page)  # Mark the page as crawled\n",
        "    return index, graph  # Return the index and graph\n",
        "\n",
        "# I wrote the lookup function to look up pages associated with a keyword in the index\n",
        "def lookup(index, keyword):\n",
        "    if keyword in index:\n",
        "        return index[keyword]  # Return the list of pages for the keyword\n",
        "    else:\n",
        "        return None  # Return None if the keyword is not found\n",
        "\n",
        "\n",
        "# Run the crawlWeb function with a seed URL to see the resulting graph\n",
        "index1, graph1 = crawlWeb(\"https://searchengineplaces.com.tr/\")"
      ],
      "metadata": {
        "id": "JfBy3VOUdcjE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I printed the elements in the graph to visualize the connections between pages\n",
        "print(f\"The graph has {len(graph1)} elements. These are:\")\n",
        "for i, (page, outlinks) in enumerate(graph1.items(), 1):\n",
        "    print(f\"{i}.\\t[{page}] : {outlinks}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZyBM1lOdfJ9",
        "outputId": "b86f7124-7d93-482a-84b4-a06a0bea7948"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The graph has 10 elements. These are:\n",
            "1.\t[https://searchengineplaces.com.tr/] : ['http://www.searchengineplaces.com.tr/travel_guide.html']\n",
            "2.\t[http://www.searchengineplaces.com.tr/travel_guide.html] : ['http://www.searchengineplaces.com.tr/ankara.html', 'http://www.searchengineplaces.com.tr/konya.html', 'http://www.searchengineplaces.com.tr/istanbul.html', 'http://www.searchengineplaces.com.tr/oktayrecommends.html', 'http://www.searchengineplaces.com.tr/seymarecommends.html']\n",
            "3.\t[http://www.searchengineplaces.com.tr/seymarecommends.html] : ['http://www.searchengineplaces.com.tr/oktayrecommends.html', 'http://www.searchengineplaces.com.tr/konya.html']\n",
            "4.\t[http://www.searchengineplaces.com.tr/oktayrecommends.html] : ['http://www.searchengineplaces.com.tr/istanbul.html']\n",
            "5.\t[http://www.searchengineplaces.com.tr/istanbul.html] : ['http://www.searchengineplaces.com.tr/maidens_tower.html', 'http://www.searchengineplaces.com.tr/galata_tower.html']\n",
            "6.\t[http://www.searchengineplaces.com.tr/galata_tower.html] : ['http://www.searchengineplaces.com.tr/istanbul.html', 'http://www.searchengineplaces.com.tr/travel_guide.html']\n",
            "7.\t[http://www.searchengineplaces.com.tr/maidens_tower.html] : ['http://www.searchengineplaces.com.tr/istanbul.html', 'http://www.searchengineplaces.com.tr/travel_guide.html']\n",
            "8.\t[http://www.searchengineplaces.com.tr/konya.html] : ['http://www.searchengineplaces.com.tr/seymarecommends.html', 'http://www.searchengineplaces.com.tr/mevlana.html']\n",
            "9.\t[http://www.searchengineplaces.com.tr/mevlana.html] : ['http://www.searchengineplaces.com.tr/travel_guide.html']\n",
            "10.\t[http://www.searchengineplaces.com.tr/ankara.html] : []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I wrote the computeRanks function to calculate the page ranks based on the graph structure\n",
        "def computeRanks(graph):\n",
        "    d = 0.8  # Damping factor for rank calculation\n",
        "    N = len(graph)  # Number of pages\n",
        "    numloops = 10  # Number of iterations to refine ranks\n",
        "    ranks = {}\n",
        "\n",
        "    # Initialize ranks: assign each page an equal rank initially\n",
        "    for page in graph:\n",
        "        ranks[page] = 1 / N\n",
        "\n",
        "    # Run the rank calculation for a set number of iterations\n",
        "    for i in range(numloops):\n",
        "        newranks = {}\n",
        "        for page in graph:\n",
        "            newrank = (1 - d) / N  # Base rank contribution\n",
        "            for node in graph:\n",
        "                if page in graph[node]:  # If the page is linked to another page\n",
        "                    newrank += d * (ranks[node] / len(graph[node]))  # Update rank based on linked pages\n",
        "            newranks[page] = newrank  # Update the rank for the page\n",
        "        ranks = newranks  # Update ranks after each iteration\n",
        "\n",
        "    return ranks  # Return the final calculated ranks\n",
        "\n",
        "# I computed and printed the ranks of the pages in the graph\n",
        "ranks1 = computeRanks(graph1)\n",
        "for page, rank in ranks1.items():\n",
        "    print(f\"The rank of the page {page} : {rank}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DTNL4JsdoOf",
        "outputId": "f439da4c-4bc9-492a-9851-8cd1e78b9f73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The rank of the page https://searchengineplaces.com.tr/ : 0.019999999999999997\n",
            "The rank of the page http://www.searchengineplaces.com.tr/travel_guide.html : 0.14780429869056003\n",
            "The rank of the page http://www.searchengineplaces.com.tr/seymarecommends.html : 0.073060618584064\n",
            "The rank of the page http://www.searchengineplaces.com.tr/oktayrecommends.html : 0.073060618584064\n",
            "The rank of the page http://www.searchengineplaces.com.tr/istanbul.html : 0.17460832634470402\n",
            "The rank of the page http://www.searchengineplaces.com.tr/galata_tower.html : 0.09025810358272002\n",
            "The rank of the page http://www.searchengineplaces.com.tr/maidens_tower.html : 0.09025810358272002\n",
            "The rank of the page http://www.searchengineplaces.com.tr/konya.html : 0.073060618584064\n",
            "The rank of the page http://www.searchengineplaces.com.tr/mevlana.html : 0.04928445079552\n",
            "The rank of the page http://www.searchengineplaces.com.tr/ankara.html : 0.043776167788544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I wrote the rankedLookup function to sort pages by their ranks for a specific keyword\n",
        "def rankedLookup(index, keyword, graph):\n",
        "    pages = index.get(keyword, [])  # Get the pages associated with the keyword\n",
        "    ranks = computeRanks(graph)  # Compute the ranks of the pages\n",
        "    unique_pages = set(pages)  # Remove duplicate pages\n",
        "    return sorted(unique_pages, key=lambda page: ranks.get(page, 0), reverse=True)  # Sort pages by rank\n",
        "\n",
        "# I ran the ranked lookup for the keyword \"in\" and printed the results\n",
        "results = rankedLookup(index1, \"in\", graph1)\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8d537hado9w",
        "outputId": "8d8ccb97-f68b-4fa6-c78b-4f29fcdc5c54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://www.searchengineplaces.com.tr/istanbul.html\n",
            "http://www.searchengineplaces.com.tr/travel_guide.html\n",
            "http://www.searchengineplaces.com.tr/maidens_tower.html\n",
            "http://www.searchengineplaces.com.tr/galata_tower.html\n",
            "http://www.searchengineplaces.com.tr/konya.html\n",
            "http://www.searchengineplaces.com.tr/mevlana.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I wrote an updated lookup function to handle multiple argument cases\n",
        "def lookup(index, keyword, *args):\n",
        "    if len(args) == 0:\n",
        "        pages = set(index.get(keyword, []))  # Get pages for the keyword\n",
        "        return list(pages)\n",
        "    elif len(args) == 2:\n",
        "        graph, computeProcedure = args  # Get the graph and rank computation procedure\n",
        "        ranks = computeProcedure(graph)  # Compute the ranks\n",
        "        pages = set(index.get(keyword, []))  # Get pages for the keyword\n",
        "        return sorted(pages, key=lambda page: ranks.get(page, 0), reverse=True)  # Sort by rank\n",
        "    elif len(args) == 1:\n",
        "        return \"Warning: Unexpected number of arguments. Provide either 2 or 4 arguments.\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid number of arguments provided to the lookup function.\")  # Raise an error if incorrect arguments are provided"
      ],
      "metadata": {
        "id": "Uq2TntoLdrUO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I tested the lookup function with and without ranks\n",
        "see = lookup(index1, \"in\", graph1, computeRanks)\n",
        "for e in see:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQRRGMcudtP-",
        "outputId": "da1e4946-0e05-4de9-8488-b7764c28fd9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://www.searchengineplaces.com.tr/istanbul.html\n",
            "http://www.searchengineplaces.com.tr/travel_guide.html\n",
            "http://www.searchengineplaces.com.tr/maidens_tower.html\n",
            "http://www.searchengineplaces.com.tr/galata_tower.html\n",
            "http://www.searchengineplaces.com.tr/konya.html\n",
            "http://www.searchengineplaces.com.tr/mevlana.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "see1 = lookup(index1, \"in\")\n",
        "for e in see1:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZBKu69gduwQ",
        "outputId": "81b0e381-c109-4dc1-82f0-d6d26e8dbbc0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://www.searchengineplaces.com.tr/istanbul.html\n",
            "http://www.searchengineplaces.com.tr/maidens_tower.html\n",
            "http://www.searchengineplaces.com.tr/galata_tower.html\n",
            "http://www.searchengineplaces.com.tr/travel_guide.html\n",
            "http://www.searchengineplaces.com.tr/konya.html\n",
            "http://www.searchengineplaces.com.tr/mevlana.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I ensured that the rankedLookup and lookup functions return the same results\n",
        "assert rankedLookup(index1, \"in\", graph1) == lookup(index1, \"in\", graph1, computeRanks)"
      ],
      "metadata": {
        "id": "VII-wd81dxUr"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}